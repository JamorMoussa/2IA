{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa42bf1-62d0-4775-9698-20c97892e762",
   "metadata": {},
   "source": [
    "# Linear Regression  \n",
    "> #### Moussa JAMOR :\n",
    "> [https://github.com/JamorMoussa/2IA](https://github.com/JamorMoussa/2IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8adabb-abf6-42f7-a636-41f5c895395d",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* #### [The Math of Linear Regression](#m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30665e2-a323-4382-81ff-83956d2599fc",
   "metadata": {},
   "source": [
    "## What's Linear Regression :  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4825f9b-55cb-430d-88c9-c8699ab93df0",
   "metadata": {},
   "source": [
    "**Linear Regression** is a classic machine learning algorithm, that predict the linear relationship between an independent variable $x$ and a dependent variable $y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb643c43-9bb6-4b3f-98db-c30f284cc979",
   "metadata": {},
   "source": [
    "Let the training data $S = \\left \\{(x_i, y_i) \\right \\}_{i = 0}^{m}$, where $x_i \\in \\mathbb{R}^d$ and $y \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0463d0-3207-492b-aca3-22f7d04c421c",
   "metadata": {},
   "source": [
    "The purpose is find a regressor $h_s$ such as : \n",
    "\n",
    "$$ h_s(x) = w^T.x + w_0 \\Longleftrightarrow  h_s(x) = w^T.x $$\n",
    "\n",
    "where $w \\in \\mathbb{R}^{d+1} $ by including the bias $w_0$, and x = $\\begin{bmatrix}\n",
    "                                                                            1 \\\\\n",
    "                                                                           x_1 \\\\\n",
    "                                                                           \\vdots \\\\\n",
    "                                                                           x_d \\\\\n",
    "                                                                          \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf20ff2-99e5-47da-9b34-b0408c303549",
   "metadata": {},
   "source": [
    "The vector $w$ is inistized randomly, the purpose is make $h_s$ close to $y$ as much as possible, at least for the training examples $S$ we have. To formalize this, we define a function that measure how close $h_s(x_i)$ to label $y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09e350-2097-4f69-9dfb-881f83935334",
   "metadata": {},
   "source": [
    "We define the **Mean squared error** as our **Cost function :** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a076f-a633-447f-9abb-f2cb86719992",
   "metadata": {},
   "source": [
    "$$ J(w) = \\frac{1}{m} \\sum_{i=1}^{m} (h_s(x_i) - y_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820d3b2-bb38-43c8-b889-81cb0c6a7e6b",
   "metadata": {},
   "source": [
    "We aim to select the parameter vector $w$ to minimize the cost function $J(w)$. To achieve this, we employ a search algorithm that commences with an initial guess $w_0$ and iteratively updates the model parameters $w$ until the cost function $J(w)$ is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad35545-f670-4f25-af28-631531df4659",
   "metadata": {},
   "source": [
    "Specialy, let consider a [Gradient descent algorithm](https://en.wikipedia.org/wiki/Gradient_descent), which start with $w_0$ and peatedly performs the update : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091e7f5-00b9-48f5-ad79-6885ddf384ab",
   "metadata": {},
   "source": [
    "$$ w_{i+1} = w_{i} - \\alpha . \\frac{\\partial J(w)}{\\partial w}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55719975-3db9-4197-ae0d-9186e71abfa8",
   "metadata": {},
   "source": [
    "where $\\alpha$ is an hyperparamters for the model, called **learning rate** it controle the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645aa95-25b4-4944-a67e-baf3e9a00909",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9165f528-fc2c-457a-bbad-b4b1ef03e174",
   "metadata": {},
   "source": [
    "## The Math of Linear Regression <a class=\"anchor\" id=\"m1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e91bf5-4764-4753-af03-a0ea83504c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ae7264-c218-4e54-a2e0-6f66f2555463",
   "metadata": {},
   "source": [
    "### The LMS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d17e8-6e03-4d32-aff5-f9144c776896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ce7a8-edb1-4dea-a6bf-266acd22178a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793fa0f-50ec-4b40-92e7-d3f4d400ef5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9876f0b-b625-45f9-91a6-2ff3f60005bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424f6f4-3fe2-4ab1-bae1-c134344fc6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d19e78-fda7-4559-aa8d-53a8c494b81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bc320-ab99-45d9-a1fe-3e5870d74462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
